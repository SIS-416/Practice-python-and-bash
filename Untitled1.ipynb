{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cba6e6c-c13e-4e48-acf3-ecf70d2abece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakib\n"
     ]
    }
   ],
   "source": [
    "print(\"shakib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0744331-0b69-4404-95af-09d100697c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 25 images belonging to 1 classes.\n",
      "Data loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asishack/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-08-05 09:16:33.104939: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-08-05 09:16:33.154944: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "2025-08-05 09:16:33.175866: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "2025-08-05 09:16:33.183919: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "/home/asishack/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17498/1070817096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m             ]\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "\n",
    "# Define directories and parameters\n",
    "train_dir = '/home/asishack/Desktop/python/practice/Forest images/'\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "\n",
    "# Define directories and parameters\n",
    "train_dir = '/home/asishack/Desktop/python/practice/Forest images/'\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "\n",
    "# Define directories and parameters\n",
    "train_dir = '/home/asishack/Desktop/python/practice/Forest images/'\n",
    "test_dir = '/home/asishack/Desktop/python/practice/cactus-images/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and prepare data from folder\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Directory not found - {e}. Please check the path and ensure images exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Check your image files or class structure.\")\n",
    "\n",
    "# Build the CNN Model (only if data loads successfully)\n",
    "if 'train_generator' in locals():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save('cnn_model.h5')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"Model training skipped due to data loading error.\")\n",
    "test_dir = '/home/asishack/Desktop/python/practice/cactus-images/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and prepare data from folder\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Directory not found - {e}. Please check the path and ensure images exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Check your image files or class structure.\")\n",
    "\n",
    "# Build the CNN Model (only if data loads successfully)\n",
    "if 'train_generator' in locals():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save('cnn_model.h5')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"Model training skipped due to data loading error.\")\n",
    "test_dir = '/home/asishack/Desktop/python/practice/cactus-images/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load and prepare data from folder\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Directory not found - {e}. Please check the path and ensure images exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Check your image files or class structure.\")\n",
    "\n",
    "# Build the CNN Model (only if data loads successfully)\n",
    "if 'train_generator' in locals():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save('cnn_model.h5')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"Model training skipped due to data loading error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb3096-da2f-46c0-8a11-5e3bfc5c485a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "debd84cc-e9a7-4261-91e2-2b304f117cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train directory: True\n",
      "Train dir contents: ['E6E290A9-300C-4390-B0B9-6F0847841F93.jpeg', '488B8D89-10B3-4C3D-937D-B3D04650F369.jpeg', '3E917659-B4C0-42B4-9C3C-ED188396DD67.jpeg', '3A286795-0C40-4D0D-ABBE-00D382FB3924.jpeg', '7BA05098-09C6-42D6-9F7E-3F62C3B42393.jpeg', '7885B060-A5F9-4BB7-BA31-DF7B2B2162E0.jpeg', 'C190511A-34D0-43BD-AF12-553F597EE3B0.jpeg', 'DA9EF1F5-B6DE-4636-94A3-48E9AD1827C4.jpeg', 'C908005B-79E7-413D-B6B2-A05E21B4B19B.jpeg', '1E175F97-2760-419E-BDBE-1BC75989F287.jpeg', '836C3EB4-720A-4E40-ABFE-AF63F2C9446F.jpeg', '1C807A45-9F73-462E-9B99-C25A72C19819.jpeg', '233E56C4-3962-421D-A6A5-285F6DC680FA.jpeg', 'A2B64927-3607-4A1A-87FD-A72DCBB7A6F6.jpeg', 'B86FC23E-B6C7-4A7C-83F8-8C8F3FF77741.jpeg', 'BFC10250-5F27-422A-B163-0C7BA70E0A91.jpeg', '70ABF382-5029-49BB-833B-2C9753B0845E.jpeg', 'F6B8DF28-435E-4A0F-81FC-D7398E886AE2.jpeg', '5B6DC350-0456-4C56-850C-B18D7C8523B9.jpeg', 'BDF33008-C918-4768-B2BC-9BC25F00BF34.jpeg', 'D7DE7251-3896-4CAB-99D5-7D4226C45E71.jpeg', '51560427-40CC-451D-8D11-BEAB8F986CD0.jpeg', '50E5C741-9BB8-45D5-89F4-A2189173EA58.jpeg', '22544158-5669-4208-8222-23EB05741DDD.jpeg', 'DF76B6EE-F97A-4195-8578-8DA36D82889C.jpeg', '5A6622C1-CED4-4C9D-8902-0D1A5E5E2065.jpeg', '56CACB75-3365-469D-9FBF-910027EE6798.jpeg', '62FFF1F2-58DC-4729-8CAD-612324FA2BC0.jpeg', '997665DE-EFFD-4FA8-9594-05608F83FFC4.jpeg', '97C075C9-0E77-4EAD-A5FA-02469B136F96.jpeg', '7BEE5690-AB89-46F3-B416-904D202AC72A.jpeg', '373C2667-713E-467D-A225-0CABE8CE7F90.jpeg', '1138CF08-9CB9-4C5F-9298-DEEA130BD7F3.jpeg', 'B72082F6-C3AD-4311-BBEF-713D39A06E5C.jpeg', 'DE00CADD-F41C-4A56-8B64-B5FD4711F2D0.jpeg', '5C2E58B8-B874-431B-A266-2569ECFF0D5C.jpeg', 'A20D93F6-D286-4477-92B9-73AE99696B9C.jpeg', '1283FB6C-B233-4693-959B-5119649F6D57.jpeg', '2AD0334C-660C-4BAB-8C71-5903E2FC69D6.jpeg', '715A19CC-91DB-4BC5-AF5F-6CE6BA7932A8.jpeg', '480BA06E-4551-4D0C-81F7-2E64F97C632B.jpeg', '2C7D2882-A5E7-49C2-AF19-F6A521255449.jpeg', 'BF873E07-3C53-4CE8-86B0-ED6CBA9CF323.jpeg', '92F0CA50-09E2-420D-ACD5-5B2A74CE2DD4.jpeg', 'DA805E27-6DDF-4E81-B95F-968C4260CC56.jpeg', '4FE6EB86-C4AA-4367-B6D9-B39DF7E6CCB1.jpeg', '17BCA8E7-A390-48A0-95AC-3F4E1C4F7AC3.jpeg', '98DECA2C-1D4A-4A88-BB7B-8B947E76F4B6.jpeg', '5019F3C8-8A77-4BDD-9DE6-F2424673E0FF.jpeg', '3CA8318F-983C-497D-BD77-1FDCA7060C21.jpeg', '3713623F-EB73-40F8-B4E8-DC64CB88B3D1.jpeg', '4FFA2A25-D971-419C-83EB-77CEBE8B2D2D.jpeg']\n",
      "Checking test directory: True\n",
      "Test dir contents: ['BDCBD63D-560F-4EEC-B6E4-1E4C54C9F28E.jpeg', 'A888C26B-4DF1-41A5-BB21-117A02F2A83E.jpeg', 'EFCF36C6-2086-4683-952E-17F3951D74A2.jpeg', 'AAC68304-6962-40C5-9DD7-C1EF3C3EF0C8.jpeg', '24B10E98-B214-4FFD-84B3-9B8E3C085702.jpeg', '8DC54264-9791-4523-BBBC-2A83B61862EE.jpeg', '14586F94-7709-4237-B42E-68A75AAE655C.jpeg', 'C009A8CD-B997-4174-A998-A80F987C7BB9.jpeg', 'A4A155C7-D0F0-4D1F-8677-52C23C99868C.jpeg', '1EB2A8AE-534E-4560-82E8-50F76DDFACCF.jpeg', '79192C8B-1BDF-4301-91F9-F925D6CC66B8.jpeg', 'BC944BD3-956C-4815-8137-E64D298FB6FE.jpeg', 'D0F7682F-0AAC-4737-BD68-ACCF8634C9F8.jpeg', '559A3EE8-D20C-4A18-BF3F-6DD2C008EC75.jpeg', '89161CC9-0A48-4BD2-AD9A-4029352E6BAC.jpeg', '93D7056F-BB47-4668-BF6D-55B04DCE7D38.jpeg', '2C5BF4D1-55BB-4588-A88E-9B77D326DD69.jpeg', '3B2FEBDD-A494-46EC-8345-47BB32064708.jpeg', 'B1446BE0-FDC2-45B4-9DA4-E2CB0CEED4DE.jpeg', 'F5990EA1-104F-49CC-B7D9-40FBA6765EED.jpeg', 'C9F65FF2-8667-430E-855E-C15EB786F309.jpeg', '99AA1B52-1488-4ECE-B8C7-714273AD8DCD.jpeg', 'C6DA42A7-61F1-48EC-8800-6D14DBFF504B.jpeg', 'C77146B1-1541-4E42-A04C-59C841690DA2.jpeg', 'CCB6C98A-7151-4A57-90BB-86FB8FD3EDA4.jpeg']\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Data loaded successfully.\n",
      "Found 0 classes in training data.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17498/2911717043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m             ]\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "\n",
    "# Define directories and parameters\n",
    "train_dir = '/home/asishack/Desktop/python/practice/Forest images/'\n",
    "test_dir = '/home/asishack/Desktop/python/practice/cactus-images/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Debug: Check if directories exist and list contents\n",
    "print(\"Checking train directory:\", os.path.exists(train_dir))\n",
    "print(\"Train dir contents:\", os.listdir(train_dir))\n",
    "print(\"Checking test directory:\", os.path.exists(test_dir))\n",
    "print(\"Test dir contents:\", os.listdir(test_dir))\n",
    "\n",
    "# Load and prepare data from folder\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Found {train_generator.num_classes} classes in training data.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Directory not found - {e}. Please check the path and ensure images exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Check your image files or class structure.\")\n",
    "    exit()\n",
    "\n",
    "# Build the CNN Model (only if data loads successfully)\n",
    "if 'train_generator' in locals():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(train_generator.num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save('cnn_model.h5')\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "else:\n",
    "    print(\"Model training skipped due to data loading error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf2d42-812c-4c68-bd41-6e76297fd6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2011f7dc-9cfe-449b-8627-f64596c4f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train directory: True\n",
      "Train dir contents: ['E6E290A9-300C-4390-B0B9-6F0847841F93.jpeg', '488B8D89-10B3-4C3D-937D-B3D04650F369.jpeg', '3E917659-B4C0-42B4-9C3C-ED188396DD67.jpeg', '3A286795-0C40-4D0D-ABBE-00D382FB3924.jpeg', '7BA05098-09C6-42D6-9F7E-3F62C3B42393.jpeg', '7885B060-A5F9-4BB7-BA31-DF7B2B2162E0.jpeg', 'C190511A-34D0-43BD-AF12-553F597EE3B0.jpeg', 'DA9EF1F5-B6DE-4636-94A3-48E9AD1827C4.jpeg', 'C908005B-79E7-413D-B6B2-A05E21B4B19B.jpeg', '1E175F97-2760-419E-BDBE-1BC75989F287.jpeg', '836C3EB4-720A-4E40-ABFE-AF63F2C9446F.jpeg', '1C807A45-9F73-462E-9B99-C25A72C19819.jpeg', '233E56C4-3962-421D-A6A5-285F6DC680FA.jpeg', 'A2B64927-3607-4A1A-87FD-A72DCBB7A6F6.jpeg', 'B86FC23E-B6C7-4A7C-83F8-8C8F3FF77741.jpeg', 'BFC10250-5F27-422A-B163-0C7BA70E0A91.jpeg', '70ABF382-5029-49BB-833B-2C9753B0845E.jpeg', 'F6B8DF28-435E-4A0F-81FC-D7398E886AE2.jpeg', '5B6DC350-0456-4C56-850C-B18D7C8523B9.jpeg', 'BDF33008-C918-4768-B2BC-9BC25F00BF34.jpeg', 'D7DE7251-3896-4CAB-99D5-7D4226C45E71.jpeg', '51560427-40CC-451D-8D11-BEAB8F986CD0.jpeg', '50E5C741-9BB8-45D5-89F4-A2189173EA58.jpeg', '22544158-5669-4208-8222-23EB05741DDD.jpeg', 'DF76B6EE-F97A-4195-8578-8DA36D82889C.jpeg', '5A6622C1-CED4-4C9D-8902-0D1A5E5E2065.jpeg', '56CACB75-3365-469D-9FBF-910027EE6798.jpeg', '62FFF1F2-58DC-4729-8CAD-612324FA2BC0.jpeg', '997665DE-EFFD-4FA8-9594-05608F83FFC4.jpeg', '97C075C9-0E77-4EAD-A5FA-02469B136F96.jpeg', '7BEE5690-AB89-46F3-B416-904D202AC72A.jpeg', '373C2667-713E-467D-A225-0CABE8CE7F90.jpeg', '1138CF08-9CB9-4C5F-9298-DEEA130BD7F3.jpeg', 'B72082F6-C3AD-4311-BBEF-713D39A06E5C.jpeg', 'DE00CADD-F41C-4A56-8B64-B5FD4711F2D0.jpeg', '5C2E58B8-B874-431B-A266-2569ECFF0D5C.jpeg', 'A20D93F6-D286-4477-92B9-73AE99696B9C.jpeg', '1283FB6C-B233-4693-959B-5119649F6D57.jpeg', '2AD0334C-660C-4BAB-8C71-5903E2FC69D6.jpeg', '715A19CC-91DB-4BC5-AF5F-6CE6BA7932A8.jpeg', '480BA06E-4551-4D0C-81F7-2E64F97C632B.jpeg', '2C7D2882-A5E7-49C2-AF19-F6A521255449.jpeg', 'BF873E07-3C53-4CE8-86B0-ED6CBA9CF323.jpeg', '92F0CA50-09E2-420D-ACD5-5B2A74CE2DD4.jpeg', 'DA805E27-6DDF-4E81-B95F-968C4260CC56.jpeg', '4FE6EB86-C4AA-4367-B6D9-B39DF7E6CCB1.jpeg', '17BCA8E7-A390-48A0-95AC-3F4E1C4F7AC3.jpeg', '98DECA2C-1D4A-4A88-BB7B-8B947E76F4B6.jpeg', '5019F3C8-8A77-4BDD-9DE6-F2424673E0FF.jpeg', '3CA8318F-983C-497D-BD77-1FDCA7060C21.jpeg', '3713623F-EB73-40F8-B4E8-DC64CB88B3D1.jpeg', '4FFA2A25-D971-419C-83EB-77CEBE8B2D2D.jpeg']\n",
      "Checking test directory: True\n",
      "Test dir contents: ['BDCBD63D-560F-4EEC-B6E4-1E4C54C9F28E.jpeg', 'A888C26B-4DF1-41A5-BB21-117A02F2A83E.jpeg', 'EFCF36C6-2086-4683-952E-17F3951D74A2.jpeg', 'AAC68304-6962-40C5-9DD7-C1EF3C3EF0C8.jpeg', '24B10E98-B214-4FFD-84B3-9B8E3C085702.jpeg', '8DC54264-9791-4523-BBBC-2A83B61862EE.jpeg', '14586F94-7709-4237-B42E-68A75AAE655C.jpeg', 'C009A8CD-B997-4174-A998-A80F987C7BB9.jpeg', 'A4A155C7-D0F0-4D1F-8677-52C23C99868C.jpeg', '1EB2A8AE-534E-4560-82E8-50F76DDFACCF.jpeg', '79192C8B-1BDF-4301-91F9-F925D6CC66B8.jpeg', 'BC944BD3-956C-4815-8137-E64D298FB6FE.jpeg', 'D0F7682F-0AAC-4737-BD68-ACCF8634C9F8.jpeg', '559A3EE8-D20C-4A18-BF3F-6DD2C008EC75.jpeg', '89161CC9-0A48-4BD2-AD9A-4029352E6BAC.jpeg', '93D7056F-BB47-4668-BF6D-55B04DCE7D38.jpeg', '2C5BF4D1-55BB-4588-A88E-9B77D326DD69.jpeg', '3B2FEBDD-A494-46EC-8345-47BB32064708.jpeg', 'B1446BE0-FDC2-45B4-9DA4-E2CB0CEED4DE.jpeg', 'F5990EA1-104F-49CC-B7D9-40FBA6765EED.jpeg', 'C9F65FF2-8667-430E-855E-C15EB786F309.jpeg', '99AA1B52-1488-4ECE-B8C7-714273AD8DCD.jpeg', 'C6DA42A7-61F1-48EC-8800-6D14DBFF504B.jpeg', 'C77146B1-1541-4E42-A04C-59C841690DA2.jpeg', 'CCB6C98A-7151-4A57-90BB-86FB8FD3EDA4.jpeg']\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Data loaded successfully.\n",
      "Found 0 classes in training data.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17498/1566233710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m             ]\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "\n",
    "# Define directories and parameters\n",
    "train_dir = '/home/asishack/Desktop/python/practice/Forest images/'\n",
    "test_dir = '/home/asishack/Desktop/python/practice/cactus-images/'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Debug: Check if directories exist and list contents\n",
    "print(\"Checking train directory:\", os.path.exists(train_dir))\n",
    "print(\"Train dir contents:\", os.listdir(train_dir))\n",
    "print(\"Checking test directory:\", os.path.exists(test_dir))\n",
    "print(\"Test dir contents:\", os.listdir(test_dir))\n",
    "\n",
    "# Load and prepare data from folder\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Found {train_generator.num_classes} classes in training data.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Directory not found - {e}. Please check the path and ensure images exist.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Check your image files or class structure.\")\n",
    "    exit()\n",
    "\n",
    "# Build the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('/home/asishack/Desktop/python/practice/cnn_model.h5')\n",
    "print(\"Model trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f622ad6d-ce73-4c90-8d72-18ee3229c74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/home/asishack/Desktop/python/practice/cnn_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17498/656378597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/asishack/Desktop/python/practice/cnn_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define image dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/asishack/Desktop/python/practice/cnn_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('/home/asishack/Desktop/python/practice/cnn_model.h5')\n",
    "\n",
    "# Define image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Predict function\n",
    "def predict_images(folder_path):\n",
    "    # Define class labels (replace with your actual class names)\n",
    "    class_labels = ['class1', 'class2']  # Update with actual class names from training\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load {filename}. Skipping...\")\n",
    "                continue\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            img = img / 255.0\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            prediction = model.predict(img)\n",
    "            class_idx = np.argmax(prediction)\n",
    "            if class_idx < len(class_labels):\n",
    "                print(f\"{filename}: Predicted as {class_labels[class_idx]} ({prediction[0][class_idx]:.4f})\")\n",
    "            else:\n",
    "                print(f\"{filename}: Prediction index out of range ({class_idx})\")\n",
    "\n",
    "# Predict on a folder of images\n",
    "predict_folder = 'Desktop/python/practice/binary_images'\n",
    "if os.path.exists(predict_folder):\n",
    "    predict_images(predict_folder)\n",
    "else:\n",
    "    print(f\"Error: Directory {predict_folder} not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc3e62-e487-4ffe-8d31-d481ad86c011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef4c06-6a1f-4e67-a96a-656893628c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69092c08-3503-41cd-b7f9-f53b22661f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
